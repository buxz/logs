# 1.使用场景
1. 解决应用耦合
2. 异步消息
3. 流量削峰
4. 实现高性能，高可用，可伸缩和最终一致性

## 1. 异步处理
>用户注册成功之后，需要发送注册邮件和注册短信
1. 串行方式(耗时150ms约1000/150=7QPS)
    - 将注册信息写入数据库（50ms），发送注册邮件（50ms），发送注册短信（50ms）
2. 并行方式(耗时100ms / 10QPS)
    - 将注册信息写入数据库（50ms），发送注册邮件并发送注册短信（50ms）
3. 使用消息队列（50ms/ 2QPS）
    - 改造非必须的业务逻辑
    - 发送邮件和发送短信交由消息队列异步处理,写入消息队列的速度很快，耗时不计

## 2. 应用解耦
>用户下单成功后，订单系统需要通知库存系统
1. 传统做法
    - 订单系统调用库存系统接口
    - 若库存系统无法访问，则订单减库存失败，从而订单失败
    - 订单系统和库存系统耦合
2. 消息队列
    - 订单系统，用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。
    - 库存系统，订阅下单消息，采用拉/推方式获取下单信息，进行库存操作
    - 即便库存系统异常，也不影响正常下单。

## 3.流量削峰
>秒杀或者团抢活动，一般会因为流量过大，导致流量暴增，应用挂掉，需要在应用前端加入消息队列
- 控制活动的人数
- 缓解短时间内高流量压垮应用
- 用户的请求，在服务器接收之后，首先写入消息队列。若消息队列长度超过最大数量，则直接抛弃用户请求或者跳转到错误页面
- 秒杀业务根据消息队列中的请求信息，再做后续处理

## 4.日志处理
>将消息队列用在日志处理中，解决大量日志传输的问题(如Kafka应用)
- 日志采集客户端，负责日志数据采集，定时写受写入Kafka队列
- kafka消息队列，负责日志数据的接收、存储、转发
- 日志处理应用，订阅并消费kafka队列中的日志数据
1. 新浪Kafka日志处理应用案列
    - kafka, 接收用户日志的消息队列
    - Logstash, 做日志分析，统一成Json输出给Elasticsearch
    - Elasticsearch, 实时日志分析服务的核心技术，一个schemaless,实时的数据存储服务，通过index组织数据，兼具强大的搜索和统计功能
    - Kibana,基于 Elasticsearch的数据可视化组件，超强的数据可视化能力是众多公司选择ELK stack的重要原因


https://mp.weixin.qq.com/s/vtiCvMMHppT17SbCeSH7Yg
